{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from scipy.io import loadmat\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ndarray_description(x):\n",
    "    return \"shape: {}, min: {}, max: {}\".format(x.shape, x.min(), x.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X shape: (5000, 401), min: -0.13196323019852488, max: 1.127688299158888\n",
      "y shape: (5000, 1), min: 1, max: 10\n"
     ]
    }
   ],
   "source": [
    "datafile = 'data/ex4data1.mat'\n",
    "mat = loadmat(datafile)\n",
    "X, y = mat['X'], mat['y']\n",
    "\n",
    "# insert column of ones\n",
    "X = np.insert(X, 0, 1, axis=1)\n",
    "\n",
    "print(\"X\", ndarray_description(X))  # 5000 images with 400 pixels (20x20)\n",
    "print(\"y\", ndarray_description(y))  # Labeled classification 1-10, 10 represents 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-0.5, 399.5, 19.5, -0.5)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1152x144 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sample = np.random.choice(X.shape[0], 20)  # 20 row indices from X\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(16, 2))\n",
    "ax.imshow(X[sample, 1:].reshape(-1, 20).T, cmap='gray_r')  # 0 index is 1 constant\n",
    "ax.axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['__header__', '__version__', '__globals__', 'Theta1', 'Theta2'])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights = loadmat('data/ex4weights.mat')\n",
    "weights.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "theta1 shape: (25, 401), min: -1.463369318005054, max: 1.0089920104197974\n",
      "theta2 shape: (10, 26), min: -4.030847527504247, max: 3.2115848427114373\n",
      "params shape: (10285,), min: -4.030847527504247, max: 3.2115848427114373\n"
     ]
    }
   ],
   "source": [
    "theta1, theta2 = weights['Theta1'], weights['Theta2']\n",
    "print(\"theta1\", ndarray_description(theta1))\n",
    "print(\"theta2\", ndarray_description(theta2))\n",
    "\n",
    "params = np.r_[theta1.ravel(), theta2.ravel()]  # quick way to create an array\n",
    "print(\"params\", ndarray_description(params))    # flattened vector of all params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feed Forward and Cost functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sigmoid gradient\n",
    "#### $$ g'(z) = g(z)(1 - g(z))$$\n",
    "where $$ g(z) = \\frac{1}{1+e^{-z}}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(z):\n",
    "    return (1 / (1 + np.exp(-z)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid_gradient(z):\n",
    "    return (sigmoid(z) * (1-sigmoid(z)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cost Function \n",
    "#### $$ J(\\theta) = \\frac{1}{m}\\sum_{i=1}^{m}\\sum_{k=1}^{K}\\big[-y^{(i)}_{k}\\, log\\,(( h_\\theta\\,(x^{(i)}))_k)-(1-y^{(i)}_k)\\,log\\,(1-h_\\theta(x^{(i)}))_k)\\big]$$\n",
    "\n",
    "### Regularized Cost Function\n",
    "#### $$ J(\\theta) = \\frac{1}{m}\\sum_{i=1}^{m}\\sum_{k=1}^{K}\\bigg[-y^{(i)}_{k}\\, log\\,(( h_\\theta\\,(x^{(i)}))_k)-(1-y^{(i)}_k)\\,log\\,(1-h_\\theta(x^{(i)}))_k)\\bigg] + \\frac{\\lambda}{2m}\\bigg[\\sum_{j=1}^{25}\\sum_{k=1}^{400}(\\Theta_{j,k}^{(1)})^2+\\sum_{j=1}^{10}\\sum_{k=1}^{25}(\\Theta_{j,k}^{(2)})^2\\bigg]$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "K - number of units (excluding the bias) in layer l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_propagate(X, theta1, theta2):\n",
    "    m = X.shape[0]  # 5000\n",
    "    a1 = X          # 5000x401, 5000 examples with 401 units to map to next layer\n",
    "    \n",
    "    z2 = theta1.dot(a1.T)  # 25x401 * 401x5000 = 25x5000\n",
    "    a2 = np.insert(sigmoid(z2.T), 0, values=np.ones(m), axis=1) # 5000x26, 5000 examples with 26 units\n",
    "    \n",
    "    z3 = theta2.dot(a2.T)  # 10x26 * 26x5000 = 10x5000\n",
    "    a3 = sigmoid(z3.T)     # 5000x10, 5000 examples with 10 output units (h vector)\n",
    "    \n",
    "    return a1, z2, a2, z3, a3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cost(params, input_layer_size, hidden_layer_size, num_labels, X, y, learning_rate):\n",
    "    # Reshape params into arrays for each layer\n",
    "    theta1 = params[0:(hidden_layer_size*(input_layer_size+1))].reshape(hidden_layer_size, (input_layer_size+1))\n",
    "    theta2 = params[(hidden_layer_size*(input_layer_size+1)):].reshape(num_labels, (hidden_layer_size+1))\n",
    "    \n",
    "    m = X.shape[0]  # 5000\n",
    "    y_matrix = pd.get_dummies(y.ravel()).values  # ndarray (5000, 10)\n",
    "    \n",
    "    # Forward propagate\n",
    "    a1, z2, a2, z3, a3 = forward_propagate(X, theta1, theta2)\n",
    "    \n",
    "    # Cost calculation, sums 5000x10 arrays\n",
    "    J = -1*(1/m) * np.sum((np.log(a3)*(y_matrix) + np.log(1-a3)*(1-y_matrix))) # scalar\n",
    "    \n",
    "    # add regulation term\n",
    "    reg = (learning_rate/(2*m)) * ( np.sum(np.square(theta1[:, 1:])) + np.sum(np.square(theta2[:, 1:])) )  # scalar\n",
    "    J += reg\n",
    "    \n",
    "    # d - error of each node\n",
    "    d3 = a3 - y_matrix  # 5000x10, 5000 examples with 10 node error values in layer 3\n",
    "    d2 = theta2[:, 1:].T.dot(d3.T) * sigmoid_gradient(z2)  # 25x10*10x5000 .* 25x5000 = 25x5000\n",
    "    d2 = d2.T           # 5000x25, 5000 examples with 25 node error values in layer 2\n",
    "    \n",
    "    # deltas - error value for each theta value\n",
    "    delta1 = d2.T.dot(a1)    # 25x5000*5000x401 = 25x401\n",
    "    delta2 = d3.T.dot(a2)    # 10x5000*5000x26  = 10x26\n",
    "    \n",
    "    # replace first coumn of theta values with 1, for bias\n",
    "    # c_ creates arrays with columns\n",
    "    theta1_ = np.c_[np.ones((theta1.shape[0], 1)), theta1[:, 1:]]  # 25x401\n",
    "    theta2_ = np.c_[np.ones((theta2.shape[0], 1)), theta2[:, 1:]]  # 10x26\n",
    "    \n",
    "    # compute theta gradients\n",
    "    theta1_grad = delta1/m + (theta1_*reg)/m\n",
    "    theta2_grad = delta2/m + (theta2_*reg)/m\n",
    "    \n",
    "    # unravel the theta matrices into a single array (a tuple)\n",
    "    grad = np.concatenate((np.ravel(theta1_grad), np.ravel(theta2_grad)))\n",
    "    \n",
    "    return J, grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "J, grad = cost(params, 400, 25, 10, X, y, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost with given theta weights: 0.28762916516131887\n"
     ]
    }
   ],
   "source": [
    "print(\"Cost with given theta weights:\", J)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "grad shape: (10285,), min: -0.0019544251591015957, max: 0.0025968523726689185\n"
     ]
    }
   ],
   "source": [
    "print(\"grad\", ndarray_description(grad))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initial random params shape: (10285,), min: -0.12499945018789832, max: 0.12494644920413536\n"
     ]
    }
   ],
   "source": [
    "input_size = 400\n",
    "hidden_size = 25\n",
    "num_labels = 10\n",
    "learning_rate = 1\n",
    "\n",
    "# randomly initialize a parameter array of the size of the full network's parameters\n",
    "params = (np.random.random(size=hidden_size * (input_size + 1) + num_labels * (hidden_size + 1)) - 0.5) * 0.25\n",
    "print(\"initial random params\", ndarray_description(params))\n",
    "\n",
    "# unravel the parameter array into parameter matrices for each layer\n",
    "theta1 = np.matrix(np.reshape(params[:hidden_size * (input_size + 1)], (hidden_size, (input_size + 1))))\n",
    "theta2 = np.matrix(np.reshape(params[hidden_size * (input_size + 1):], (num_labels, (hidden_size + 1))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "a1, z2, a2, z3, h = forward_propagate(X, theta1, theta2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial cost 7.148742290984698\n",
      "Initial gradient shape: (10285,), min: -0.04400231354948956, max: 0.4742170108285923\n"
     ]
    }
   ],
   "source": [
    "J, grad = cost(params, input_size, hidden_size, num_labels, X, y, learning_rate)\n",
    "print(\"Initial cost\", J)\n",
    "print(\"Initial gradient\", ndarray_description(grad))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "     fun: 0.41517849683673425\n",
       "     jac: array([ 5.37076792e-04, -1.75763816e-06, -4.46982889e-06, ...,\n",
       "       -4.18455385e-04, -4.28146970e-04, -3.27424216e-05])\n",
       " message: 'Max. number of function evaluations reached'\n",
       "    nfev: 250\n",
       "     nit: 18\n",
       "  status: 3\n",
       " success: False\n",
       "       x: array([-0.25938728, -0.03013275, -0.07663025, ...,  0.72323524,\n",
       "       -1.24598204, -0.56611822])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scipy.optimize import minimize\n",
    "\n",
    "# minimize the the parameters with cost and grad calculations\n",
    "fmin = minimize(fun=cost, x0=params, args=(input_size, hidden_size, num_labels, X, y, learning_rate),\n",
    "                method='TNC', jac=True, options={'maxiter': 250})\n",
    "fmin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fmin.x, the optimized parameter values shape: (10285,), min: -8.029154708569443, max: 5.678796956552972\n"
     ]
    }
   ],
   "source": [
    "opt_params = fmin.x\n",
    "print(\"fmin.x, the optimized parameter values\", ndarray_description(opt_params))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fmin.jac, the optimized gradient values shape: (10285,), min: -0.0019035907656762485, max: 0.0018258976533056545\n"
     ]
    }
   ],
   "source": [
    "opt_grads = fmin.jac\n",
    "print(\"fmin.jac, the optimized gradient values\", ndarray_description(opt_grads))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "opt_theta1 shape: (25, 401), min: -2.140541304193211, max: 2.0850281068778354\n"
     ]
    }
   ],
   "source": [
    "opt_theta1 = fmin.x[0:(25*(400+1))].reshape(25, (400+1))\n",
    "print(\"opt_theta1\", ndarray_description(opt_theta1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "opt_theta2 shape: (10, 26), min: -8.029154708569443, max: 5.678796956552972\n"
     ]
    }
   ],
   "source": [
    "opt_theta2 = fmin.x[(25*(400+1)):].reshape(10, (25+1))\n",
    "print(\"opt_theta2\", ndarray_description(opt_theta2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_pred shape: (5000,), min: 1, max: 10\n"
     ]
    }
   ],
   "source": [
    "a1, z2, a2, z3, h = forward_propagate(X, opt_theta1, opt_theta2)\n",
    "y_pred = np.array(np.argmax(h, axis=1) + 1)\n",
    "print(\"y_pred\", ndarray_description(y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 99.16\n"
     ]
    }
   ],
   "source": [
    "correct = [1 if a == b else 0 for (a, b) in zip(y_pred, y)]\n",
    "accuracy = (sum(map(int, correct)) /  float(len(correct)))\n",
    "print(\"Accuracy:\", accuracy*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient checking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_gradient(thetas, deltas, X, y, learning_rate):\n",
    "    \"\"\"Check that 10 random gradient values are properly decreasing.\n",
    "    \n",
    "    \n",
    "    \"\"\"\n",
    "    eps = 0.0001  # 10e-4\n",
    "    n_elements = len(thetas)\n",
    "    \n",
    "    # pick 10 random examples to test\n",
    "    for i in range(10):\n",
    "        x = int(np.random.rand()*n_elements)\n",
    "        \n",
    "        eps_vector = np.zeros((n_elements, 1))\n",
    "        eps_vector[x] = eps\n",
    "        eps_vector = eps_vector.ravel()\n",
    "        \n",
    "        cost_high, _ = cost(thetas + eps_vector, 400, 25, 10, X, y, learning_rate)\n",
    "        cost_low, _ = cost(thetas - eps_vector, 400, 25, 10, X, y, learning_rate)\n",
    "        approximate_grad = (cost_high - cost_low) / float(2*eps)\n",
    "        print(\"Example {}: gradient {} ~= approximate {}\".format(x, deltas[x], approximate_grad))\n",
    "        print(\"        {}: difference {}\".format(x, deltas[x] - approximate_grad))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example 6279: gradient 9.895619448182038e-06 ~= approximate 5.253998625054379e-06\n",
      "        6279: difference 4.641620823127659e-06\n",
      "Example 9383: gradient -6.794103233781901e-06 ~= approximate 2.0885324858443965e-05\n",
      "        9383: difference -2.7679428092225867e-05\n",
      "Example 3014: gradient -1.7016001298300037e-05 ~= approximate -6.714003020213966e-05\n",
      "        3014: difference 5.012402890383962e-05\n",
      "Example 4842: gradient -3.1982395415763385e-06 ~= approximate -1.0248908388632572e-05\n",
      "        4842: difference 7.050668847056233e-06\n",
      "Example 409: gradient 3.4944243357858516e-06 ~= approximate 1.4623992572460054e-05\n",
      "        409: difference -1.1129568236674202e-05\n",
      "Example 4053: gradient 3.96699864942952e-06 ~= approximate 1.3726218217602337e-05\n",
      "        4053: difference -9.759219568172816e-06\n",
      "Example 7657: gradient -3.2009903686856975e-06 ~= approximate -8.876264168122816e-06\n",
      "        7657: difference 5.675273799437118e-06\n",
      "Example 6625: gradient -0.0001614903008413506 ~= approximate -7.575394256331691e-05\n",
      "        6625: difference -8.57363582780337e-05\n",
      "Example 8096: gradient 0.00015188512697462072 ~= approximate 0.00015303560751966927\n",
      "        8096: difference -1.1504805450485514e-06\n",
      "Example 8928: gradient 7.450661510004263e-06 ~= approximate 6.264801455380109e-06\n",
      "        8928: difference 1.1858600546241541e-06\n"
     ]
    }
   ],
   "source": [
    "check_gradient(opt_params, opt_grads, X, y, learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
