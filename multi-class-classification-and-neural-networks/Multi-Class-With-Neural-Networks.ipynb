{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multi-class Classification and Neural Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import scipy.io  # Used to load the OCTAVE *.mat files\n",
    "\n",
    "import scipy.misc                    # Used to show matrix as an image\n",
    "from scipy.optimize import minimize  # minimizes parameteres with cost and grad functions\n",
    "\n",
    "import matplotlib.cm as cm       # Used to display images in a specific colormap\n",
    "import random\n",
    "from scipy.special import expit  # Vectorized sigmoid function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ndarray_description(x):\n",
    "    return \"shape: {}, min: {}, max: {}\".format(x.shape, x.min(), x.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "datafile = 'data/ex3data1.mat'\n",
    "mat = scipy.io.loadmat(datafile)\n",
    "X, y = mat['X'], mat['y']\n",
    "\n",
    "# insert column of ones\n",
    "X = np.insert(X, 0, 1, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X shape: (5000, 401), min: -0.13196323019852488, max: 1.127688299158888\n",
      "y shape: (5000, 1), min: 1, max: 10\n"
     ]
    }
   ],
   "source": [
    "print(\"X\", ndarray_description(X))  # 5000 images with 400 pixels (20x20)\n",
    "print(\"y\", ndarray_description(y))  # Labeled classification 1-10, 10 represents 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-0.5, 399.5, 19.5, -0.5)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1152x144 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sample = np.random.choice(X.shape[0], 20)  # 20 row indices from X\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(16, 2))\n",
    "ax.imshow(X[sample, 1:].reshape(-1,20).T, cmap='gray_r')  # 0 index is 1 constant\n",
    "ax.axis('off')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multi-class Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic regression hypothesis\n",
    "#### $$ h_{\\theta}(x) = g(\\theta^{T}x)$$\n",
    "#### $$ g(z)=\\frac{1}{1+e^{−z}} $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hypothesis(theta, X):\n",
    "    \"\"\"Vectorized computation of the hypothesis for each example X with a set of theta values.\n",
    "    \n",
    "    X dot theta takes 401 values in a row of X (a vector) and multiples them with the 401 theta\n",
    "    vector. A.t * B = B.t * A if both are vectors, so this vectorizes the g(theta.t * x)\n",
    "    logistic hypothesis for all 5000 examples in X.\n",
    "    \n",
    "    :param numpy.ndarray theta: 401x1 vector of theta values\n",
    "    :param numpy.ndarray X: 5000x401 matrix of examples\n",
    "    \n",
    "    :returns: 5000x1 array\n",
    "    :rtype: numpy.ndarray\n",
    "    \"\"\"\n",
    "    return expit(np.dot(X, theta))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cost function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regularized Cost Function \n",
    "#### $$ J(\\theta) = \\frac{1}{m}\\sum_{i=1}^{m}\\big[-y^{(i)}\\, log\\,( h_\\theta\\,(x^{(i)}))-(1-y^{(i)})\\,log\\,(1-h_\\theta(x^{(i)}))\\big] + \\frac{\\lambda}{2m}\\sum_{j=1}^{n}\\theta_{j}^{2}$$\n",
    "### Vectorized Cost Function\n",
    "#### $$ J(\\theta) = \\frac{1}{m}\\big((\\,log\\,(g(X\\theta))^Ty+(\\,log\\,(1-g(X\\theta))^T(1-y)\\big) + \\frac{\\lambda}{2m}\\sum_{j=1}^{n}\\theta_{j}^{2}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cost(theta, X, y, learning_rate=0.): \n",
    "    \"\"\"Calculate the total cost for every example with a set of parameter values.\n",
    "    \n",
    "    :param numpy.ndarray theta: A vector of parameter values (401x1)\n",
    "    :param numpy.ndarray X: An array of examples (5000x401)\n",
    "    :param numpy.ndarray y: The labeled prediction vector (5000x1)\n",
    "    :param float learning_rate: value to tune the weight regularization holds on the cost function\n",
    "    \n",
    "    :rtype: np.array[numpy.float64]\n",
    "    \"\"\"\n",
    "    m = X.shape[0]            # 5000\n",
    "    h = hypothesis(theta, X)  # 5000x1 vector\n",
    "    \n",
    "    # use dot product to sum all terms in y * log(h) vectors\n",
    "    term1 = np.log(h).T.dot(-1*y)   # scalar\n",
    "    term2 = np.log(1-h).T.dot(1-y)  # scalar\n",
    "    reg = (learning_rate/(2*m)) * np.sum(np.square(theta[1:]))  # scalar, exclude theta[0]\n",
    "    \n",
    "    J = (1/m)*(term1-term2) + reg  # still 1x1 vectors\n",
    "    \n",
    "    if np.isnan(J[0]):\n",
    "        return np.inf\n",
    "    \n",
    "    return J[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regularized Gradient\n",
    "\n",
    "#### $$ \\frac{\\delta J(\\theta)}{\\delta\\theta_{j}} = \\frac{1}{m}\\sum_{i=1}^{m} ( h_\\theta (x^{(i)})-y^{(i)})x^{(i)}_{j} + \\frac{\\lambda}{m}\\theta_{j}$$ \n",
    "### Vectorized Gradient\n",
    "#### $$ \\frac{\\delta J(\\theta)}{\\delta\\theta_{j}} = \\frac{1}{m} X^T(g(X\\theta)-y) + \\frac{\\lambda}{m}\\theta_{j}$$\n",
    "##### $$\\text{Note: intercept parameter } \\theta_{0} \\text{ is not to be regularized}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cost_gradient(theta, X, y, learning_rate=0.):\n",
    "    \"\"\"Calculate the gradient for every theta value.\n",
    "    \n",
    "    :param numpy.ndarray theta: A vector of parameter values (401x1)\n",
    "    :param numpy.ndarray X: An array of examples (5000x401)\n",
    "    :param numpy.ndarray y: The labeled prediction vector (5000x1)\n",
    "    :param float learning_rate: value to tune the weight regularization holds on the gradient function\n",
    "    \n",
    "    :returns: 401x5000 array\n",
    "    :rtype: numpy.ndarray\n",
    "    \"\"\"\n",
    "    m = X.shape[0]                          # 5000\n",
    "    h = hypothesis(theta, X).reshape(-1,1)  # 5000x1 vector\n",
    "    \n",
    "    beta = h - y\n",
    "    reg = ((1.0/m) * initial_theta[1:]).reshape(-1,1)  # 400x1\n",
    "    reg = np.insert(reg, 0, 0).reshape(-1,1)           # insert a 0 for theta[0], 401x1\n",
    "    \n",
    "    grad = (1/m) * X.T.dot(beta)                       # 401x1\n",
    "    \n",
    "    return (grad + reg).flatten()  # 401x1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Computations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initial_theta shape: (401, 1), min: 0.0, max: 0.0\n"
     ]
    }
   ],
   "source": [
    "# initial_theta = np.random.uniform(X.min(), X.max(), (X.shape[1], 1)) for random values\n",
    "initial_theta = np.zeros((X.shape[1], 1))\n",
    "print(\"initial_theta\", ndarray_description(initial_theta))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "h shape: (5000, 1), min: 0.5, max: 0.5\n"
     ]
    }
   ],
   "source": [
    "h = hypothesis(initial_theta, X)  # 5000x1\n",
    "print(\"h\", ndarray_description(h))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "J shape: (1,), min: 160.39425758157174, max: 160.39425758157174\n"
     ]
    }
   ],
   "source": [
    "J = cost(initial_theta, X, y)\n",
    "print(\"J\", ndarray_description(J))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "g shape: (401,), min: -5.0, max: 0.004095720569551439\n"
     ]
    }
   ],
   "source": [
    "g = cost_gradient(initial_theta, X, y)\n",
    "print(\"g\", ndarray_description(g))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## One vs All Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_vs_all(features, classes, K, learning_rate):\n",
    "    \"\"\"Compute optimal parameters for the features (X) to each class 1...K (y).\n",
    "        \n",
    "    :param numpy.ndarray features: An array of examples with n columns and m rows (5000x401)\n",
    "    :param numpy.ndarray classes: The labeled prediction vector, m rows and 1 column (5000x1)\n",
    "    :param int K: The number of classes in the classes array\n",
    "    :param float learning_rate: parameter to tune the weight regularization holds on the cost function\n",
    "    \n",
    "    :returns: an array of theta values for each class, 10x401\n",
    "    :rtype: numpy.ndarray\n",
    "    \"\"\"\n",
    "    initial_theta = np.zeros((X.shape[1], 1))  # 401x1\n",
    "    all_thetas = np.zeros((K, X.shape[1]))     # 10x401\n",
    "    \n",
    "    # labels 1 to 10\n",
    "    for c in np.arange(1, K+1):\n",
    "        res = minimize(cost, initial_theta, args=(X, (classes == c)*1, learning_rate),\n",
    "                       method=None, jac=cost_gradient, options={'maxiter': 50})\n",
    "        all_thetas[c-1] = res.x  # res.x is (401,) ndarray\n",
    "    \n",
    "    return all_thetas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "optimal_thetas shape: (10, 401), min: -8.597227620895094, max: 2.69050229712157\n"
     ]
    }
   ],
   "source": [
    "optimal_thetas = one_vs_all(X, y, 10, 0.1)\n",
    "print(\"optimal_thetas\", ndarray_description(optimal_thetas))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_one_vs_all(theta, X):\n",
    "    \"\"\"Returns a vector of class predictions (1-10) for each row in X.\n",
    "    \n",
    "    :param numpy.ndarray theta: An array where each row contains a set of theta values, 10x401\n",
    "    :param numpy.ndarray X: An array where each row contains the bias + variables, 5000x401\n",
    "    \n",
    "    :returns: An array of predictions (1-10) for each example, 5000x1\n",
    "    :rtype: numpy.ndarray\n",
    "    \"\"\"\n",
    "    # For each example (row) in X, compute the probability it belongs to each class\n",
    "    # transpose theta to get 5000x401 * 401x10 (X.dot(theta))\n",
    "    probability = expit(np.dot(X, theta.T))    # 5000x10\n",
    "    \n",
    "    # Each row in probability is an array of the probability for each class 0-9\n",
    "    # find the highest probability in each row, take it's index and add one for 1-10\n",
    "    # return a vector of predictions 1-10\n",
    "    return np.argmax(probability, axis=1) + 1  # 5000x1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "One vs all accuracy: 93.26\n"
     ]
    }
   ],
   "source": [
    "predictions = predict_one_vs_all(optimal_thetas, X)\n",
    "\n",
    "# compare each prediction to y, add them all up, and take average of matches\n",
    "accuracy = np.mean(predictions == y.ravel()) * 100\n",
    "print(\"One vs all accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predictions with sklearn\n",
    "Try using a known model instead of computing one vs all."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=10, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr',\n",
       "          n_jobs=None, penalty='l2', random_state=None, solver='liblinear',\n",
       "          tol=0.0001, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# C - Inverse of regularization strength\n",
    "# penalty - norm used in the penalization\n",
    "# solver - Algorithm to use in the optimization problem\n",
    "# specified multi_class to its default to avoid a future warning\n",
    "clf = LogisticRegression(C=10, penalty='l2', solver='liblinear', multi_class='ovr')\n",
    "\n",
    "# Scikit inserts the intercept (first column of 1s) so exclude it from my X\n",
    "clf.fit(X[:, 1:], y.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SKLearn's model accuracy: 93.26\n"
     ]
    }
   ],
   "source": [
    "model_predictions = clf.predict(X[:, 1:])\n",
    "model_accuracy = np.mean(predictions == y.ravel()) * 100\n",
    "print(\"SKLearn's model accuracy:\", model_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Networks\n",
    "A Neural NeFirst load given optimized theta values for each layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "theta1 shape: (25, 401), min: -1.463369318005054, max: 1.0089920104197974\n",
      "theta2 shape: (10, 26), min: -4.030847527504247, max: 3.2115848427114373\n"
     ]
    }
   ],
   "source": [
    "datafile = 'data/ex3weights.mat'\n",
    "mat = scipy.io.loadmat(datafile)\n",
    "theta1, theta2 = mat[\"Theta1\"], mat[\"Theta2\"]\n",
    "\n",
    "print(\"theta1\", ndarray_description(theta1))\n",
    "print(\"theta2\", ndarray_description(theta2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_propagate(X, theta1, theta2):\n",
    "    \"\"\"Calculate the a and z arrays with given thetas for each layer.\n",
    "    \n",
    "    :param numpy.ndarray X: array of 5000x401 input units (includes bias)\n",
    "    :param numpy.ndarray theta1: array of 25x401 parameters for layer1\n",
    "    :param numpy.ndarray theta2: array of 10x26 paramters for layer2\n",
    "    \n",
    "    :returns: ndarray's for a1, z2, a2, z3, and h\n",
    "    \"\"\"\n",
    "    m = X.shape[0]  # 5000\n",
    "    a1 = X          # 5000x401\n",
    "\n",
    "    z2 = a1.dot(theta1.T)                                    # 5000x25\n",
    "    a2 = np.insert(expit(z2), 0, values=np.ones(m), axis=1)  # 5000x26\n",
    "\n",
    "    z3 = a2.dot(theta2.T)  # 5000x10\n",
    "    h = expit(z3)           # 5000x10\n",
    "    \n",
    "    return a1, z2, a2, z3, h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [],
   "source": [
    "a1, z2, a2, z3, h = forward_propagate(X, theta1, theta2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each row in h contains an array of probabilities for each class 0-9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.12661530e-04, 1.74127856e-03, 2.52696959e-03, 1.84032321e-05,\n",
       "       9.36263860e-03, 3.99270267e-03, 5.51517524e-03, 4.01468105e-04,\n",
       "       6.48072305e-03, 9.95734012e-01])"
      ]
     },
     "execution_count": 268,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a 5000x1 vector of predictions, 1-10 (the index with the greatest probability)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predictions shape: (5000,), min: 1, max: 10\n"
     ]
    }
   ],
   "source": [
    "predictions = np.argmax(h, axis=1)+1  # (5000,) ndarray 1-10\n",
    "print(\"predictions\", ndarray_description(predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compare the predictions to y and find the accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Neural Network accuracy: 97.52\n"
     ]
    }
   ],
   "source": [
    "accuracy = np.mean(predictions == y.ravel())*100\n",
    "print(\"Neural Network accuracy:\", accuracy)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
