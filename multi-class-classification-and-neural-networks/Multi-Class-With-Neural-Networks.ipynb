{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multi-class Classification and Neural Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import scipy.io  # Used to load the OCTAVE *.mat files\n",
    "\n",
    "import scipy.misc                    # Used to show matrix as an image\n",
    "from scipy.optimize import minimize  # minimizes parameteres with cost and grad functions\n",
    "\n",
    "import matplotlib.cm as cm       # Used to display images in a specific colormap\n",
    "import random\n",
    "from scipy.special import expit  # Vectorized sigmoid function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ndarray_description(x):\n",
    "    return \"shape: {}, min: {}, max: {}\".format(x.shape, x.min(), x.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "datafile = 'data/ex3data1.mat'\n",
    "mat = scipy.io.loadmat(datafile)\n",
    "X, y = mat['X'], mat['y']\n",
    "\n",
    "# insert column of ones\n",
    "X = np.insert(X, 0, 1, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X shape: (5000, 401), min: -0.13196323019852488, max: 1.127688299158888\n",
      "y shape: (5000, 1), min: 1, max: 10\n"
     ]
    }
   ],
   "source": [
    "print(\"X\", ndarray_description(X))  # 5000 images with 400 pixels (20x20)\n",
    "print(\"y\", ndarray_description(y))  # Labeled classification 1-10, 10 represents 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-0.5, 399.5, 19.5, -0.5)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1152x144 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sample = np.random.choice(X.shape[0], 20)  # 20 row indices from X\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(16, 2))\n",
    "ax.imshow(X[sample, 1:].reshape(-1,20).T, cmap='gray_r')  # 0 index is 1 constant\n",
    "ax.axis('off')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multi-class Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Logistic regression hypothesis\n",
    "#### $$ h_{\\theta}(x) = g(\\theta^{T}x)$$\n",
    "#### $$ g(z)=\\frac{1}{1+e^{âˆ’z}} $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hypothesis(theta, X):\n",
    "    \"\"\"Vectorized computation of the hypothesis for each example X with a set of theta values.\n",
    "    \n",
    "    X dot-product theta takes 401 x(i) values in a row of X (a vector) and\n",
    "    multiples them with the 401 theta vector values. A.t * B = B.t * A if both are \n",
    "    vectors, so this vectorizes the g(theta.t * x) logistic hypothesis for all 5000\n",
    "    examples in X.\n",
    "    \n",
    "    :param numpy.ndarray theta: 401x1 vector of theta values\n",
    "    :param numpy.ndarray X: 5000x401 matrix of examples\n",
    "    \n",
    "    :returns: 5000x1 array\n",
    "    :rtype: numpy.ndarray\n",
    "    \"\"\"\n",
    "    return expit(np.dot(X, theta))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cost function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Regularized Cost Function \n",
    "#### $$ J(\\theta) = \\frac{1}{m}\\sum_{i=1}^{m}\\big[-y^{(i)}\\, log\\,( h_\\theta\\,(x^{(i)}))-(1-y^{(i)})\\,log\\,(1-h_\\theta(x^{(i)}))\\big] + \\frac{\\lambda}{2m}\\sum_{j=1}^{n}\\theta_{j}^{2}$$\n",
    "#### Vectorized Cost Function\n",
    "#### $$ J(\\theta) = \\frac{1}{m}\\big((\\,log\\,(g(X\\theta))^Ty+(\\,log\\,(1-g(X\\theta))^T(1-y)\\big) + \\frac{\\lambda}{2m}\\sum_{j=1}^{n}\\theta_{j}^{2}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cost(theta, X, y, learning_rate=0.): \n",
    "    \"\"\"Calculate the total cost for every example with a set of parameter values.\n",
    "    \n",
    "    Set learning_rate to non-zero to include regularization.\n",
    "\n",
    "    :param numpy.ndarray theta: An n- dimensional vector of parameter values (401x1)\n",
    "    :param numpy.ndarray X: An array of examples with n columns and m rows (5000x401)\n",
    "    :param numpy.ndarray y: The labeled prediction vector, m rows and 1 column (5000x1)\n",
    "    :param float learning_rate: parameter to tune the weight regularization holds on the cost function\n",
    "    \n",
    "    :rtype: np.array[numpy.float64]\n",
    "    \"\"\"\n",
    "    m = X.shape[0]            # 5000\n",
    "    h = hypothesis(theta, X)  # 5000x1 vector\n",
    "    \n",
    "    # use dot product to sum all terms in y * log(h) vectors\n",
    "    term1 = np.log(h).T.dot(-1*y)   # scalar\n",
    "    term2 = np.log(1-h).T.dot(1-y)  # scalar\n",
    "    reg = (learning_rate/(2*m)) * np.sum(np.square(theta[1:]))  # scalar, exclude theta[0]\n",
    "    \n",
    "    J = (1/m)*(term1-term2) + reg  # still 1x1 vectors\n",
    "    \n",
    "    if np.isnan(J[0]):\n",
    "        return np.inf\n",
    "    \n",
    "    return J[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initial_theta shape: (401, 1), min: 0.0, max: 0.0\n"
     ]
    }
   ],
   "source": [
    "# initial_theta = np.random.uniform(X.min(), X.max(), (X.shape[1], 1))  # 401x1\n",
    "initial_theta = np.zeros((X.shape[1],1))\n",
    "print(\"initial_theta\", ndarray_description(initial_theta))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "h shape: (5000, 1), min: 0.5, max: 0.5\n"
     ]
    }
   ],
   "source": [
    "h = hypothesis(initial_theta, X)  # 5000x1\n",
    "print(\"h\", ndarray_description(h))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "J shape: (1,), min: 160.39425758157174, max: 160.39425758157174\n"
     ]
    }
   ],
   "source": [
    "J = cost(initial_theta, X, y)\n",
    "print(\"J\", ndarray_description(J))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Regularized Gradient\n",
    "\n",
    "#### $$ \\frac{\\delta J(\\theta)}{\\delta\\theta_{j}} = \\frac{1}{m}\\sum_{i=1}^{m} ( h_\\theta (x^{(i)})-y^{(i)})x^{(i)}_{j} + \\frac{\\lambda}{m}\\theta_{j}$$ \n",
    "#### ...vectorized\n",
    "#### $$ \\frac{\\delta J(\\theta)}{\\delta\\theta_{j}} = \\frac{1}{m} X^T(g(X\\theta)-y) + \\frac{\\lambda}{m}\\theta_{j}$$\n",
    "##### $$\\text{Note: intercept parameter } \\theta_{0} \\text{ is not to be regularized}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cost_gradient(theta, X, y, learning_rate=0.):\n",
    "    \"\"\"Calculate the gradient for every theta value.\n",
    "    \n",
    "    Set learning_rate to non-zero to include regularization.\n",
    "\n",
    "    :param numpy.ndarray theta: An n- dimensional vector of parameter values (401x1)\n",
    "    :param numpy.ndarray X: An array of examples with n columns and m rows (5000x401)\n",
    "    :param numpy.ndarray y: The labeled prediction vector, m rows and 1 column (5000x1)\n",
    "    :param float learning_rate: parameter to tune the weight regularization holds on the cost function\n",
    "    \n",
    "    :returns: 401x5000 array\n",
    "    :rtype: numpy.ndarray\n",
    "    \"\"\"\n",
    "    m = X.shape[0]                          # 5000\n",
    "    h = hypothesis(theta, X).reshape(-1,1)  # 5000x1 vector\n",
    "    \n",
    "    beta = h - y\n",
    "    reg = ((1.0/m) * initial_theta[1:]).reshape(-1,1)  # 400x1\n",
    "    reg = np.insert(reg, 0, 0).reshape(-1,1)           # insert a 0 for theta[0], 401x1\n",
    "    \n",
    "    grad = (1/m) * X.T.dot(beta)                       # 401x1\n",
    "    \n",
    "    return (grad + reg).flatten()  # 401x1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "g shape: (401,), min: -5.0, max: 0.004095720569551439\n"
     ]
    }
   ],
   "source": [
    "g = cost_gradient(initial_theta, X, y)\n",
    "print(\"g\", ndarray_description(g))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## One vs All Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_vs_all(features, classes, K, learning_rate):\n",
    "    \"\"\"Compute optimal parameters for the features (X) to each class 1...K (y).\n",
    "        \n",
    "    :param numpy.ndarray features: An array of examples with n columns and m rows (5000x401)\n",
    "    :param numpy.ndarray classes: The labeled prediction vector, m rows and 1 column (5000x1)\n",
    "    :param int K: The number of classes in the classes array\n",
    "    :param float learning_rate: parameter to tune the weight regularization holds on the cost function\n",
    "    \n",
    "    :returns: an array of theta values for each class, 10x401\n",
    "    :rtype: numpy.ndarray\n",
    "    \"\"\"\n",
    "    initial_theta = np.zeros((X.shape[1], 1))  # 401x1\n",
    "    all_thetas = np.zeros((K, X.shape[1]))     # 10x401\n",
    "    \n",
    "    # labels 1 to 10\n",
    "    for c in np.arange(1, K+1):\n",
    "        res = minimize(cost, initial_theta, args=(X, (classes == c)*1, learning_rate),\n",
    "                       method=None, jac=cost_gradient, options={'maxiter': 50})\n",
    "        all_thetas[c-1] = res.x  # res.x is (401,) ndarray\n",
    "    \n",
    "    return all_thetas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "optimal_thetas shape: (10, 401), min: -8.597227620895094, max: 2.69050229712157\n"
     ]
    }
   ],
   "source": [
    "optimal_thetas = one_vs_all(X, y, 10, 0.1)\n",
    "print(\"optimal_thetas\", ndarray_description(optimal_thetas))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_one_vs_all(theta, X):\n",
    "    \"\"\"Returns a vector of class predictions (1-10) for each row in X.\n",
    "    \n",
    "    :param numpy.ndarray theta: An array where each row contains a set of theta values, 10x401\n",
    "    :param numpy.ndarray X: An array where each row contains the bias + variables, 5000x401\n",
    "    \n",
    "    :returns: An array of predictions (1-10) for each example, 5000x1\n",
    "    :rtype: numpy.ndarray\n",
    "    \"\"\"\n",
    "    # For each example (row) in X, compute the probability it belongs to each class\n",
    "    # transpose theta to get 5000x401 * 401x10 (X.dot(theta))\n",
    "    probability = expit(np.dot(X, theta.T))    # 5000x10\n",
    "    \n",
    "    # Each row in probability is an array of the probability for each class 0-9\n",
    "    # find the highest probability in each row, take it's index and add one for 1-10\n",
    "    # return a vector of predictions 1-10\n",
    "    return np.argmax(probability, axis=1) + 1  # 5000x1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set accuracy: 93.26\n"
     ]
    }
   ],
   "source": [
    "predictions = predict_one_vs_all(optimal_thetas, X)\n",
    "\n",
    "# compare each prediction to y, add them all up, and take average of matches\n",
    "accuracy = np.mean(predictions == y.ravel()) * 100\n",
    "print(\"Training set accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predictions with sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=10, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr',\n",
       "          n_jobs=None, penalty='l2', random_state=None, solver='liblinear',\n",
       "          tol=0.0001, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# C - Inverse of regularization strength\n",
    "# penalty - norm used in the penalization\n",
    "# solver - Algorithm to use in the optimization problem\n",
    "# specified multi_class to its default to avoid a future warning\n",
    "clf = LogisticRegression(C=10, penalty='l2', solver='liblinear', multi_class='ovr')\n",
    "\n",
    "# Scikit inserts the intercept (first column of 1s) so exclude it from my X\n",
    "clf.fit(X[:, 1:], y.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set accuracy: 93.26\n"
     ]
    }
   ],
   "source": [
    "model_predictions = clf.predict(X[:, 1:])\n",
    "model_accuracy = np.mean(predictions == y.ravel()) * 100\n",
    "print(\"Training set accuracy:\", model_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Networks\n",
    "First load given optimized theta values for each layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "theta_1 shape: (25, 401), min: -1.463369318005054, max: 1.0089920104197974\n",
      "theta_2 shape: (10, 26), min: -4.030847527504247, max: 3.2115848427114373\n"
     ]
    }
   ],
   "source": [
    "datafile = 'data/ex3weights.mat'\n",
    "mat = scipy.io.loadmat(datafile)\n",
    "theta_1, theta_2 = mat[\"Theta1\"], mat[\"Theta2\"]\n",
    "print(\"theta_1\", ndarray_description(theta_1))\n",
    "print(\"theta_2\", ndarray_description(theta_2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_neural_network(theta_1, theta_2, features):\n",
    "    z2 = theta_1.dot(features.T)      # 25x401 dot 401x5000\n",
    "    a2 = expit(z2)                    # 25x5000\n",
    "    a2 = np.insert(a2, 0, 1, axis=0)  # 26x5000, insert row of 1s\n",
    "    \n",
    "    z3 = theta_2.dot(a2)  #10x5000\n",
    "    a3 = expit(z3)\n",
    "    \n",
    "    return np.argmax(a3, axis=1) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10,)"
      ]
     },
     "execution_count": 220,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn_predictions = predict_neural_network(theta_1, theta_2, X)\n",
    "nn_predictions.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set accuracy: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/joeselvik/.virtualenvs/machine-learning-coursera/lib/python3.7/site-packages/ipykernel_launcher.py:4: DeprecationWarning: elementwise == comparison failed; this will raise an error in the future.\n",
      "  after removing the cwd from sys.path.\n"
     ]
    }
   ],
   "source": [
    "# accuracy = np.mean(predictions == y.ravel()) * 100\n",
    "# print(\"Training set accuracy:\", accuracy)\n",
    "\n",
    "nn_accuracy = np.mean(nn_predictions == y.ravel()) * 100\n",
    "print(\"Training set accuracy:\", nn_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
